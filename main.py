from ctypes import alignment
import streamlit as st
import streamlit_pdf_viewer as st_pdf_viewer
import os
import logging
import json
import base64
import requests
import time
import urllib
import uuid
from urllib.parse import quote
import tempfile
import datetime

import google.auth.transport.requests
import google.oauth2.id_token
from google.cloud import storage
from google.cloud import pubsub_v1
from google.cloud import firestore
import pandas as pd
from google.cloud.firestore import Query

from vertexai.generative_models import GenerativeModel, Image, Part
from vertexai.preview.vision_models import ImageGenerationModel
from vertexai.preview.generative_models import GenerationConfig
from google import genai
from google.genai import types
from google.genai.types import (
    ControlReferenceConfig,
    ControlReferenceImage,
    EditImageConfig,
    Image,
    RawReferenceImage,
    StyleReferenceConfig,
    StyleReferenceImage,
    MaskReferenceImage,
    SubjectReferenceConfig,
    SubjectReferenceImage,
)
PROJECT_ID = "xxxxxxxxxxxxxxx"  # @param {type: "string", placeholder: "[your-project-id]", isTemplate: true}
if not PROJECT_ID or PROJECT_ID == "[your-project-id]":
    PROJECT_ID = str(os.environ.get("GOOGLE_CLOUD_PROJECT"))
LOCATION = os.environ.get("GOOGLE_CLOUD_REGION", "us-central1")

try:
    # å½“è¿è¡Œåœ¨å…·æœ‰ Firestore æƒé™çš„ GCE ä¸Šæ—¶ï¼Œå®¢æˆ·ç«¯åº“ä¼šè‡ªåŠ¨æŸ¥æ‰¾å‡­æ® (ADC)
    db = firestore.Client(project="yuchizh-test-449107")
    print(f"Firestore client initialized successfully using GCE ADC for project {PROJECT_ID}.")
except Exception as e:
    # åœ¨ Streamlit UI å’Œæ§åˆ¶å°éƒ½æ˜¾ç¤ºé”™è¯¯
    st.error(f"Firestore åˆå§‹åŒ–å¤±è´¥ (ä½¿ç”¨ ADC): {e}. è¯·æ£€æŸ¥ GCE å®ä¾‹æœåŠ¡è´¦å·æƒé™å’Œé¡¹ç›® ID ({PROJECT_ID})ã€‚")
    print(f"Firestore åˆå§‹åŒ–å¤±è´¥ (ä½¿ç”¨ ADC): {e}. è¯·æ£€æŸ¥ GCE å®ä¾‹æœåŠ¡è´¦å·æƒé™å’Œé¡¹ç›® ID ({PROJECT_ID})ã€‚")
    db = None # åˆå§‹åŒ–å¤±è´¥åˆ™å°† db è®¾ä¸º None

client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)
generation_model = "imagen-3.0-generate-002"
gcs_uri = "gs://xxxxxxxxxxxxxxx"

def log_api_call_to_firestore(db_client, user_id, api_type, details=None):
    """å°† API è°ƒç”¨äº‹ä»¶è®°å½•åˆ° Firestore (ç²¾ç®€ç‰ˆ)"""
    if not db_client:
        print("Firestore client æœªåˆå§‹åŒ–ï¼Œè·³è¿‡æ—¥å¿—è®°å½•ã€‚")
        # ä¸åœ¨ UI ä¸Šæ˜¾ç¤ºè­¦å‘Šï¼Œä¿æŒç•Œé¢ç®€æ´
        return

    # å¦‚æœ user_id ä¸ºç©ºæˆ–æ— æ•ˆï¼Œä½¿ç”¨å ä½ç¬¦
    effective_user_id = user_id if user_id else "unknown_user"

    try:
        timestamp = datetime.datetime.now(datetime.timezone.utc) # ä½¿ç”¨ UTC æ—¶é—´
        log_entry = {
            'username': effective_user_id,
            'timestamp': timestamp,
            'api_type': api_type, # API ç±»å‹ï¼Œå¦‚ 'text_to_image'
            # å¯ä»¥é€‰æ‹©æ€§åœ°æ·»åŠ  detailsï¼Œå¦‚æœè°ƒç”¨æ—¶ä¼ å…¥äº†çš„è¯
            'details': details if details else {}
        }
        # å†™å…¥åä¸º 'api_calls_log' çš„é›†åˆï¼Œå¯ä¿®æ”¹
        db_client.collection('api_calls_log').add(log_entry)
        # ä»…åœ¨æ§åˆ¶å°æ‰“å°æˆåŠŸä¿¡æ¯ï¼Œé¿å…å¹²æ‰° UI
        print(f"Firestore log success: User={effective_user_id}, Type={api_type}")
    except Exception as e:
        # ä»…åœ¨æ§åˆ¶å°æ‰“å°é”™è¯¯ä¿¡æ¯
        print(f"Firestore log error: {e}")
        # ä¸åœ¨ UI ä¸Šæ˜¾ç¤ºé”™è¯¯ï¼Œé¿å…å¹²æ‰°ç”¨æˆ·

def encode_image(image):
    with open(image, "rb") as image_file:
        encoded_string = base64.b64encode(image_file.read())
    return encoded_string

def encode_uploaded_file(uploaded_file):
    """Encodes the content of an UploadedFile to base64."""
    if uploaded_file is not None:  # Check if a file was uploaded
        file_content = uploaded_file.read()
        encoded_string = base64.b64encode(file_content)
        return encoded_string
    else:
        return None  # Or handle the case where no file was uploaded

def __videoGenerate__(token, project_id, params):
    # Get access token calling API
    creds, project = google.auth.default()
    auth_req = google.auth.transport.requests.Request()
    creds.refresh(auth_req)
    access_token = creds.token

    url = f"https://us-central1-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/us-central1/publishers/google/models/veo-2.0-generate-001:predictLongRunning"
    headers = {
        'Authorization': 'Bearer ' + access_token,
        'Content-Type': 'application/json;charset=utf-8',
    }

    # æ£€æŸ¥å¹¶å¤„ç† params ä¸­çš„ bytes ç±»å‹æ•°æ® (ä¹‹å‰çš„ä»£ç ) ...
    if isinstance(params, bytes):
        params_str = params.decode('utf-8')
        params = json.loads(params_str)
    else:  # params æ˜¯å­—å…¸
        for key, value in params.items():
            if isinstance(value, bytes):
                # å°è¯•è§£ç ä¸ºæ–‡æœ¬
                try:
                    params[key] = value.decode('utf-8')
                except UnicodeDecodeError:
                    # å¦‚æœä¸æ˜¯æ–‡æœ¬ï¼Œåˆ™è¿›è¡Œ Base64 ç¼–ç 
                    params[key] = base64.b64encode(value).decode('utf-8')


    print("Before requests.post:")
    print(type(params))
    print(params)

    response = requests.post(url, headers=headers, json=params)
    return response

def __videoFetch__(token, project_id, params):
    creds, project = google.auth.default()
    auth_req = google.auth.transport.requests.Request()
    creds.refresh(auth_req)
    access_token = creds.token
    url = f"https://us-central1-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/us-central1/publishers/google/models/veo-2.0-generate-001:fetchPredictOperation"
    headers = {
        'Authorization': 'Bearer ' + access_token,
        'Content-Type': 'application/json;charset=utf-8',
    }
    response = requests.post(url,headers=headers,json=params)
    return response

def download_video_from_gcs(bucket_name, source_blob_name):
    """Downloads a blob from the bucket."""
    storage_client = storage.Client()
    bucket = storage_client.bucket(bucket_name)
    blob = bucket.blob(source_blob_name)

    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as temp_file:
        blob.download_to_filename(temp_file.name)
        temp_file_path = temp_file.name

    return temp_file_path

def display_video_from_gcs(gcs_uri):
    """Displays a video from a GCS URI in Streamlit."""
    try:
        # Parse the GCS URI
        parts = gcs_uri.replace("gs://", "").split("/")
        bucket_name = parts[0]
        source_blob_name = "/".join(parts[1:])  # Reconstruct blob name

        # Download the video
        local_video_path = download_video_from_gcs(bucket_name, source_blob_name)

        # Display the video in Streamlit
        video_file = open(local_video_path, 'rb')
        video_bytes = video_file.read()
        st.video(video_bytes)
        video_file.close()

        # Clean up the temporary file
        os.remove(local_video_path)

    except Exception as e:
        st.error(f"Error displaying video: {e}")

def upload_to_gcs(uploaded_file, bucket_name, destination_blob_name=None):
    if uploaded_file is None:
        return None
    try:
        # å¦‚æœæœªæŒ‡å®š GCS ä¸­çš„æ–‡ä»¶åï¼Œåˆ™ç”Ÿæˆä¸€ä¸ªå”¯ä¸€çš„æ–‡ä»¶å
        if destination_blob_name is None:
            file_extension = os.path.splitext(uploaded_file.name)[1]
            destination_blob_name = f"uploads/{uuid.uuid4()}{file_extension}"

        # åˆå§‹åŒ– GCS å®¢æˆ·ç«¯
        storage_client = storage.Client()
        bucket = storage_client.bucket(bucket_name)
        blob = bucket.blob(destination_blob_name)

        uploaded_file.seek(0) 
        blob.upload_from_file(uploaded_file, content_type=uploaded_file.type)

        print(f"File {uploaded_file.name} uploaded to gs://{bucket_name}/{destination_blob_name}")

        gcs_url = f"https://storage.googleapis.com/{bucket_name}/{quote(destination_blob_name, safe='')}"
        print(f"GCS URL: {gcs_url}")
        return gcs_url

    except Exception as e:
        print(f"Error uploading to GCS: {e}")
        return None
def get_gcs_uri_from_url(url: str) -> str:
    """Converts a GCS URL to a gs:// URI."""
    if not url.startswith("https://storage.googleapis.com/"):
        raise ValueError("Invalid GCS URL")

    # Remove the base URL
    path = url.replace("https://storage.googleapis.com/", "")

    # Decode any URL-encoded characters
    decoded_path = urllib.parse.unquote(path)

    # Split the path into bucket name and blob name
    parts = decoded_path.split("/", 1)
    if len(parts) == 1:
      bucket_name = parts[0]
      blob_name = ""
    else:
      bucket_name, blob_name = parts

    # Construct the gs:// URI
    if blob_name:
      gcs_uri = f"gs://{bucket_name}/{blob_name}"
    else:
      gcs_uri = f"gs://{bucket_name}"

    return gcs_uri

def publish_to_pubsub(project_id: str, topic_id: str, message_data: dict):
    """å°†æ¶ˆæ¯å‘å¸ƒåˆ° Pub/Sub ä¸»é¢˜ã€‚"""
    publisher = None
    try:
        # åˆå§‹åŒ– Pub/Sub å‘å¸ƒè€…å®¢æˆ·ç«¯ (å‡è®¾ GOOGLE_APPLICATION_CREDENTIALS å·²è®¾ç½®)
        publisher = pubsub_v1.PublisherClient()
        topic_path = publisher.topic_path(project_id, topic_id)

        # æ•°æ®å¿…é¡»æ˜¯å­—èŠ‚ä¸² (bytestring)
        message_bytes = json.dumps(message_data).encode("utf-8")

        # å‘å¸ƒæ¶ˆæ¯æ—¶ï¼Œå®¢æˆ·ç«¯ä¼šè¿”å›ä¸€ä¸ª future å¯¹è±¡
        future = publisher.publish(topic_path, message_bytes)
        # é˜»å¡ç›´åˆ°æ¶ˆæ¯å‘å¸ƒå®Œæˆ (å¯é€‰ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨å›è°ƒ)
        message_id = future.result()
        # print(f"å·²å°†æ¶ˆæ¯ ID: {message_id} å‘å¸ƒåˆ° {topic_path}") # å¦‚æœéœ€è¦è°ƒè¯•ï¼Œå¯ä»¥ä¿ç•™
        return message_id
    except Exception as e:
        st.error(f"å‘ Pub/Sub ä¸»é¢˜ {topic_id} å‘å¸ƒæ¶ˆæ¯æ—¶å‡ºé”™: {e}")
        return None

def show_pdf_from_local_path(file_path: str):
    """ä»æœ¬åœ°æ–‡ä»¶è·¯å¾„è¯»å–å¹¶æ˜¾ç¤ºPDF"""
    try:
        with open(file_path, "rb") as f:
            base64_pdf = base64.b64encode(f.read()).decode('utf-8')
        pdf_display = f'<iframe src="data:application/pdf;base64,{base64_pdf}" width="700" height="1000" type="application/pdf"></iframe>'
        st.markdown(pdf_display, unsafe_allow_html=True)
    except FileNotFoundError:
        st.error(f"é”™è¯¯ï¼šæ–‡ä»¶æœªæ‰¾åˆ° - {file_path}")
    except Exception as e:
        st.error(f"åŠ è½½PDFæ—¶å‘ç”Ÿé”™è¯¯: {e}")

def get_user_logs(db_client, user_id):
    """æ ¹æ® user_id ä» Firestore è·å–æ—¥å¿—è®°å½•"""
    if not db_client:
        st.error("Firestore å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•è·å–è®°å½•ã€‚")
        return []
    if not user_id or "unknown" in user_id: # ä¸ä¸ºæœªçŸ¥ç”¨æˆ·æŸ¥è¯¢
        st.warning("æ— æ³•è¯†åˆ«å½“å‰ç”¨æˆ·ï¼Œæ— æ³•è·å–è®°å½•ã€‚")
        return []

    logs = []
    try:
        # æŸ¥è¯¢ç”¨æˆ·åä¸º user_id çš„æ–‡æ¡£ï¼Œå¹¶æŒ‰æ—¶é—´æˆ³é™åºæ’åº
        docs = db_client.collection('api_calls_log') \
                        .where('username', '==', user_id) \
                        .order_by('timestamp', direction=Query.DESCENDING) \
                        .stream()

        for doc in docs:
            log_data = doc.to_dict()
            log_data['id'] = doc.id # æ·»åŠ æ–‡æ¡£ IDï¼Œè™½ç„¶æš‚æ—¶ä¸ç”¨ä½†å¯èƒ½æœ‰ç”¨
            logs.append(log_data)
        print(f"ä¸ºç”¨æˆ· {user_id} ä» Firestore è·å–äº† {len(logs)} æ¡è®°å½•ã€‚") # æ§åˆ¶å°æ—¥å¿—
    except Exception as e:
        st.error(f"æŸ¥è¯¢ Firestore è®°å½•æ—¶å‡ºé”™: {e}")
        print(f"æŸ¥è¯¢ Firestore è®°å½•æ—¶å‡ºé”™ (ç”¨æˆ·: {user_id}): {e}")
        # æç¤ºå¯èƒ½éœ€è¦ç´¢å¼•
        if "index" in str(e).lower():
             st.warning("æç¤ºï¼šFirestore æŸ¥è¯¢å¯èƒ½éœ€è¦åˆ›å»ºå¤åˆç´¢å¼•ã€‚è¯·æ£€æŸ¥ Firestore æ§åˆ¶å°ä¸­çš„é”™è¯¯æç¤ºæˆ–ç´¢å¼•å»ºè®®ã€‚")
    return logs

def download_image(image_bytes, filename="upscaled_image.jpg"):
    """æä¾›ä¸‹è½½å›¾åƒçš„åŠŸèƒ½"""
    st.download_button(
        label=f"ä¸‹è½½ {filename}",
        data=image_bytes,
        file_name=filename,
        mime="image/jpeg",
    )


def main():
    log_file_path = "/PATH_TO_YOUR_LOG_FILE/app.log"
    logging.basicConfig(filename=log_file_path, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    
    st.set_page_config(layout="wide")

    # headers = _get_websocket_headers()
    headers = st.context.headers
    user_id = ""
    if headers:
        user_id_full = headers.get("X-Goog-Authenticated-User-Email")
        if user_id_full:
            # Split the string at the colon
            parts = user_id_full.split(":")
            if len(parts) > 1:
                user_id = parts[1]  # Get the part after the colon
                logging.info(f'ç”¨æˆ·ç™»å½•æˆåŠŸï¼ŒIDä¸ºï¼š{user_id}')
            else:
                st.write("Email format is incorrect.")
        else:
            st.write("X-Goog-Authenticated-User-Email header not found.")
            logging.warning("æœªæ‰¾åˆ° X-Goog-Authenticated-User-Email header")
            user_id = "unknown_no_headers"
    else:
        st.write("No HTTP headers available.")
        logging.warning("æ— æ³•è·å– HTTP headers")
        user_id = "unknown_no_headers"

    st.markdown("""
        <style>
        .stTextArea textarea {
            border-radius: 10px;
            border: 2px solid #0794f2;
            padding: 10px;
            background-color: #f8f9fa;
        }
        .stButton button {
            border-radius: 20px;
            background-color: #0794f2;
            color: white;
            padding: 10px 24px;
            border: none;
            box-shadow: 0 2px 5px rgba(0,0,0,0.2);
            transition: all 0.3s ease;
        }
        .stButton button:hover {
            background-color: #0794f2;
            box-shadow: 0 4px 8px rgba(0,0,0,0.2);
            transform: translateY(-2px);
        }
        .image-container {
            border-radius: 15px;
            padding: 20px;
            background: #ffffff;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            margin: 10px 0;
        }
        h1 {
            color: #2E7D32;
            text-align: center;
            padding: 15px;
            margin-bottom: 20px;
            font-family: 'Arial', sans-serif;
            border-bottom: 3px solid #0794f2;
        }
        img {
            border-radius: 10px;
            transition: transform 0.3s ease;
        }
        img:hover {
            transform: scale(1.00);
        }
        .centered-title {
            text-align: left;
            width: 100%;
            margin: 0 auto;
            padding: 10px 0;
        }
        
        .centered-image {
            display: flex;
            justify-content: center;
            align-items: center;
            margin: 0 auto;
            width: 60%;  /* å¯ä»¥è°ƒæ•´è¿™ä¸ªå€¼æ¥æ§åˆ¶å›¾ç‰‡å®½åº¦ */
        }
        </style>
    """, unsafe_allow_html=True)

       
    # Create sidebar with dropdown
    with st.sidebar:
        option = st.selectbox(
            'Functions',
            ('Text to Image', 'Enlarge Image', 'Edit Image', 'Image to Video', 'Text to Video', 'My Collections', 'Video Analysis', 'Batch Video Analysis')
        )
    
    left_col, right_col = st.columns([1, 9])
    
    if option == 'Text to Image':
        with left_col:
            user_prompt = st.sidebar.text_area("Type in your prompt :", height=100, key="prompt_input")
            optimize_button = st.sidebar.button("improve your prompt", help="ç‚¹å‡»ä»¥ä¼˜åŒ–æç¤ºè¯", key="optimize_button")

            # åˆå§‹åŒ– opt_prompt_input å’Œ optimize_button_clicked åœ¨ session_state ä¸­
            if "opt_prompt_input" not in st.session_state:
                st.session_state.opt_prompt_input = ""
            if "optimize_button_clicked" not in st.session_state:
                st.session_state.optimize_button_clicked = False

            if optimize_button:
                if not user_prompt:
                    st.warning("æç¤ºè¯ä¸èƒ½ä¸ºç©º!")
                else:
                    model = GenerativeModel("gemini-2.0-flash")

                    prompt = """
                    This word or sentense is the user_prompt that user input. It may be a character or animal or object. 
                    Please follow this style of text prompt: â€˜This close-up shot of a Victoria crowned pigeon 
                    showcases its striking blue plumage and red chest. Its crest is made of delicate, lacy feathers, 
                    while its eye is a striking red color. The birdâ€™s head is tilted slightly to the side, giving the 
                    impression of it looking regal and majestic. The background is blurred, drawing attention to the 
                    birdâ€™s striking appearanceâ€™ â€˜Animated scene features a close-up of a short fluffy monster kneeling 
                    beside a melting red candle. The art style is 3D and realistic, with a focus on lighting and texture. 
                    The mood of the painting is one of wonder and curiosity, as the monster gazes at the flame with wide 
                    eyes and open mouth. Its pose and expression convey a sense of innocence and playfulness, as if it is 
                    exploring the world around it for the first time. The use of warm colors and dramatic lighting further
                      enhances the cozy atmosphere of the image.â€™ â€˜Drone view of waves crashing against the rugged cliffs 
                      along Big Surâ€™s gray point beach. The crashing blue waters create white-tipped waves, while the golden 
                      light of the setting sun illuminates the rocky shore. A small island with a lighthouse sits in the 
                      distance, and green shrubbery covers the cliffâ€™s edge. The steep drop from the road down to the beach 
                      is a dramatic feat, with the cliffâ€™s edges jutting out over the sea. This is a view that captures the 
                      raw beauty of the coast and the rugged landscape of the Pacific Coast Highway.â€™ â€˜Several giant wooly mammoths 
                      approach treading through a snowy meadow, their long wooly fur lightly blows in the wind as they walk, 
                      snow covered trees and dramatic snow capped mountains in the distance, mid afternoon light with wispy clouds
                        and a sun high in the distance creates a warm glow, the low camera view is stunning capturing the large 
                        furry mammal with beautiful photography, depth of field.â€™â€˜A candid shot captures a blond 6-year-old girl 
                        strolling down a bustling city street. The warm glow of the summer sunset bathes her in golden light, 
                        casting long shadows that stretch across the pavement. The girl's hair shimmers like spun gold, her eyes 
                        sparkle with wonder as she takes in the sights and sounds around her. The blurred background of vibrant 
                        shop windows and hurrying pedestrians emphasizes her innocence and carefree spirit. The low angle of the 
                        shot adds a sense of grandeur, elevating the ordinary moment into an award-winning photograph.â€™ â€˜A close-up 
                        shot of a man made entirely of glass riding the New York City subway. Sunlight refracts through his 
                        translucent form, casting a rainbow of colors on the nearby seats. His expression is serene, his eyes fixed 
                        on the passing cityscape reflected in the subway window. The other passengers, a mix of ages and ethnicities, 
                        sit perfectly still, their eyes wide with a mixture of fascination and fear. The carriage is silent, the only 
                        sound the rhythmic clickety-clack of the train on the tracks.â€™ â€˜Close-up cinematic shot of a man in a crisp 
                        white suit, bathed in the warm glow of an orange neon sign. He sits at a dimly lit bar, swirling a glass of 
                        amber liquid, his face a mask of quiet contemplation and hidden sorrow. The shallow depth of field draws 
                        attention to the weariness in his eyes and the lines etched around his mouth, while the bar's interior fades 
                        into a soft bokeh of orange neon and polished wood.â€™ â€˜This close-up shot follows a queen as she ascends the 
                        steps of a candlelit throne room. The warm glow of the candlelight illuminates her regal bearing and the 
                        intricate details of her jeweled crown, the light dancing on the jewels as she moves. She turns her head, 
                        the wisdom in her eyes and the strength in her jawline becoming more prominent. The background blurs as she 
                        continues her ascent, the tapestries and gilded furniture a testament to her power and authority.â€™ â€˜Cinematic 
                        shot of a man dressed in a weathered green trench coat, bathed in the eerie glow of a green neon sign. 
                        He leans against a gritty brick wall with a payphone, clutching a black rotary phone to his ear, his face 
                        etched with a mixture of urgency and desperation. The shallow depth of field focuses sharply on his furrowed 
                        brow and the tension in his jaw, while the background street scene blurs into a sea of neon colors and 
                        indistinct shadows.â€™
                        
                        Consider these prompts. Based on these examples, rewrite the user_prompt based on the above style: 
                    """
                    print(user_prompt)
                    contents = [user_prompt, prompt]
                    responses = model.generate_content(contents)

                    # åœ¨åˆ›å»ºæ–‡æœ¬æ¡†ä¹‹å‰æ›´æ–° session_state
                    st.session_state.opt_prompt_input = responses.text
                    st.session_state.optimize_button_clicked = True #è®¾ç½®æŒ‰é’®ç‚¹å‡»çŠ¶æ€ä¸ºtrue

                    print("yuchiok0")
                    print(responses.text)

            opt_prompt_input = st.sidebar.text_area(
                "The prompt after optimized",
                height=100,
                key="opt_prompt_input",
                value=st.session_state.opt_prompt_input
            )
            number_of_images = st.sidebar.selectbox(
                'image number',
                ('1', '2', '3', '4')
            )
            img_frameOption = st.sidebar.selectbox(
                    'frame',
                    ('1:1','9:16','16:9','3:4','4:3')
                )
            
            generate_button = st.sidebar.button("Generate", key="generate_button")
                
        # Right column
        with right_col:            
            st.title("Google Imagen 3 Generates Image")
            text_to_highlight = """
            åœ¨æ–‡ç”Ÿå›¾çš„åœºæ™¯é‡Œï¼Œæœ‰å‡ ç‚¹æ˜¯éœ€è¦æ³¨æ„çš„ï¼Œä»¥ä¾¿äºä½ èƒ½ç”Ÿæˆè´¨é‡æ›´å¥½çš„å›¾ç‰‡ï½ \n
            æç¤ºè¯æœ€ä½³å®è·µå¯ä»¥å‚è€ƒï¼šhttps://ai.google.dev/gemini-api/docs/imagen-prompt-guide?hl=zh-cn \n
            1. å°½é‡ä¿æŒæç¤ºè¯ä¸è¦å¤ªé•¿: \n
            å¤ªé•¿çš„æç¤ºè¯å¯èƒ½ä¼šè®©æ¨¡å‹æ„Ÿåˆ°å›°æƒ‘ \n
            2. æç¤ºè¯ç»“æ„:  \n
            ç»“æ„æ¸…æ™°ï¼Œå…³é”®è¯ã€çŸ­å¥ï¼Œä¿æŒèŠ‚å¥ï½ \n
            3. å›¾åƒé£æ ¼ï¼š \n
            â€œæ—¶å°šæ‘„å½±â€ã€â€œå·¥ä½œå®¤æ‹æ‘„â€ã€â€œ3D æ¸²æŸ“â€ã€â€œå¡é€šâ€ \n
            4. è®¾å®šç›¸æœºç±»å‹ï¼š \n
            â€œç”¨æ•°ç å•åç›¸æœºæ‹æ‘„çš„ç…§ç‰‡â€â€œåœ¨ä½³èƒ½ EOS R5 ä¸Šâ€
            â€œ85mmç„¦è·â€ â€œå¾®è·æ‘„å½±â€ \n
            æ¯”å¦‚ï¼Œè¯•è¯•è¿™ä¸ªï¼š \n
            A vibrant portrait of a woman in a flowing red dress, her hair flying behind her as she sprints through a sun-drenched park, with a joyful expression on her face, captured in a dynamic, high-resolution photograph with a shallow depth of field that highlights her movement. 
            """
            st.info(text_to_highlight)
            st.markdown('<div class="centered-image">', unsafe_allow_html=True)
            # show_image = st.image("test.jpg", use_container_width =True)
            show_image_placeholder = st.empty()
            if os.path.exists("test.jpg"):
                 show_image_placeholder.image("test.jpg", use_container_width=True)
            else:
                 show_image_placeholder.markdown("*Image results will appear here*")

            if generate_button:
                if not opt_prompt_input:
                    st.warning("æç¤ºè¯ä¸èƒ½ä¸ºç©º")
                    # st.stop()
                    return

                print("Start to generate image.\n")
                logging.info("Image generating.")
                logging.info(f"ç”¨æˆ·: {user_id} æ­£åœ¨ä½¿ç”¨æ–‡ç”Ÿå›¾ï¼Œç”Ÿæˆ{number_of_images}ä¸ªå›¾ç‰‡ï¼Œæç¤ºè¯ä¸º: {opt_prompt_input}")

                try:
                    fast_images = client.models.generate_images(
                        model=generation_model,
                        prompt=opt_prompt_input,
                        config=types.GenerateImagesConfig(
                            number_of_images=number_of_images,
                            aspect_ratio=img_frameOption,
                            safety_filter_level="BLOCK_ONLY_HIGH",
                            person_generation="ALLOW_ADULT",
                        ),
                    )
                    print('type={}'.format(type(fast_images)))
                                             
                    # Imagen 3 Fast image generation
                    # cv2.imwrite("generated_image.jpg", fast_image.generated_images[0].image._pil_image)
                    if fast_images is not None:
                        show_image_placeholder.empty()
                        for idx, image in enumerate(fast_images.generated_images):
                            st.write(f"ç¬¬{idx + 1}å¼ å›¾ç‰‡ â¬‡ï¸ ")    
                            st.image(image.image._pil_image)
                            log_details = {"prompt": opt_prompt_input}
                            log_api_call_to_firestore(db, user_id, "text_to_image", details=log_details)
                    
                except (TypeError, KeyError, requests.exceptions.RequestException) as e:
                    logging.error(f"Error during image display: {e}")
                    logging.error(f"ç”¨æˆ·: {user_id} æ­£åœ¨ä½¿ç”¨æ–‡ç”Ÿå›¾ï¼Œæç¤ºè¯è¢«å’Œè°ï¼Œæç¤ºè¯ä¸º: {opt_prompt_input}")
                    st.error("å†…å®¹è¢«æ²³èŸ¹å•¦ã€‚ã€‚è¯·æ›´æ¢æç¤ºè¯")
                
                
    elif option == 'Enlarge Image':
        with left_col:
            with left_col:
                # uploaded_file = st.sidebar.file_uploader("upload the image!", type=["jpg", "jpeg", "png"])

                uploaded_files = st.sidebar.file_uploader(
                    "é€‰æ‹©å›¾ç‰‡æ–‡ä»¶",
                    type=["jpg", "jpeg", "png"], 
                    accept_multiple_files=True 
                )

            with st.sidebar:
                upscale_factor = st.selectbox(
                    'upscale factor',
                    ('x2', 'x4')
                )
                
            upscale_button = st.sidebar.button("Upscale the Image")
                
        # Right column
        with right_col:            
            st.title("Google Imagen 3 Generates Image")
            text_to_highlight = """
            æ‚¨å¯ä»¥ä½¿ç”¨ Imagen on Vertex AI çš„æ”¾å¤§åŠŸèƒ½æ¥å¢åŠ å›¾ç‰‡çš„å¤§å°ï¼Œè€Œä¸ä¼šé™ä½è´¨é‡ã€‚\n
            UPSCALE_FACTOR æ˜¯å›¾ç‰‡çš„æ”¾å¤§ç³»æ•°ã€‚å¦‚æœæœªæŒ‡å®šï¼Œç³»ç»Ÿå°†æ ¹æ®è¾“å…¥å›¾ç‰‡çš„è¾ƒé•¿è¾¹å’Œ sampleImageSize ç¡®å®šæ”¾å¤§ç³»æ•°ã€‚å¯ç”¨å€¼ï¼šx2 æˆ– x4ã€‚\n
            """
            st.info(text_to_highlight)
            st.markdown('<div class="centered-image">', unsafe_allow_html=True)
            # show_image = st.image("test.jpg", use_container_width =True)
            show_image_placeholder = st.empty()
            if os.path.exists("test.jpg"):
                 show_image_placeholder.image("test.jpg", use_container_width=True)
            else:
                 show_image_placeholder.markdown("*Image results will appear here*")

            if upscale_button:
                logging.info("Image upscaling.")
                logging.info(f"ç”¨æˆ·: {user_id} æ­£åœ¨ä½¿ç”¨å›¾ç‰‡è¶…åˆ†ï¼Œè¶…åˆ†å‚æ•°ä¸º: {upscale_factor}")
                show_image_placeholder.empty()
                st.info(f"æ­£åœ¨å¤„ç† {len(uploaded_files)} ä¸ªæ–‡ä»¶ğŸƒ") # æç¤ºä¿¡æ¯

                # è¿›åº¦æ¡
                progress_bar = st.progress(0)

                for i, uploaded_file in enumerate(uploaded_files):
                    try:
                        image_data = uploaded_file.read()
                        image = types.Image(
                                    image_bytes=image_data,
                                    mime_type="image/png",
                                )
                        
                        response = client.models.upscale_image(
                            model='imagen-3.0-generate-002',
                            image=image,
                            upscale_factor=upscale_factor,
                            config=types.UpscaleImageConfig(
                                include_rai_reason=True,
                                output_mime_type='image/jpeg',
                            ),
                        )

                        log_details = {"upscale_factor": upscale_factor}
                        if response is not None:
                            generated_image = response.generated_images[0]
                           
                            print(f"Type of generated_image.image: {type(generated_image.image)}")
                            print(f"Attributes of generated_image.image: {dir(generated_image.image)}")
                            if hasattr(generated_image.image, 'image_bytes'):
                                image_bytes = generated_image.image.image_bytes
                                filename = f"upscaled_image_{i+1}.jpg"
                                download_image(image_bytes, filename)
                                log_api_call_to_firestore(db, user_id, "image_upscale", details=log_details)
                            
                            # st.write(f"ç¬¬{i + 1}å¼ å›¾ç‰‡ â¬‡ï¸ ") 
                            # image_bytes = response.generated_images[0].image_bytes
                            # filename = f"upscaled_image_{i+1}.jpg"
                            # download_image(image_bytes, filename)
                            # st.image(response.generated_images[0].image._pil_image)
                            # log_api_call_to_firestore(db, user_id, "image_upscale", details=log_details)

                    except (TypeError, KeyError, requests.exceptions.RequestException) as e:
                        logging.error(f"Error during image display: {e}")
                        logging.error(f"ç”¨æˆ·: {user_id} æ­£åœ¨ä½¿ç”¨å›¾ç‰‡è¶…åˆ†ï¼Œè¢«å’Œè°")
                        st.error(f"ç¬¬{i}å¼ å›¾ç‰‡å†…å®¹è¢«æ²³èŸ¹å•¦ã€‚ã€‚")
                    
                    progress_bar.progress((i + 1) / len(uploaded_files))
                    time.sleep(0.1)                     

    elif option == 'Edit Image':
        with left_col:
            with left_col:
                uploaded_file = st.sidebar.file_uploader("upload the image!", type=["jpg", "jpeg", "png"])

            with st.sidebar:
                person_generation = st.sidebar.selectbox(
                    'person generation options',
                    ('allow_adult', 'dont_allow')
                )
                enhance_prompt = st.sidebar.selectbox(
                    'Need Prompt enhancement?',
                    ('True', 'False')
                )
                number_of_images = st.sidebar.selectbox(
                    'image number',
                    ('1', '2', '3', '4')
                )

                subject_type = st.sidebar.selectbox(
                    'subject type',
                    ('SUBJECT_TYPE_DEFAULT', 'SUBJECT_TYPE_PERSON', 'SUBJECT_TYPE_ANIMAL', 'SUBJECT_TYPE_PRODUCT')
                )
                
                control_type = st.sidebar.selectbox(
                    'Control type',
                    ('CONTROL_TYPE_SCRIBBLE', 'CONTROL_TYPE_FACE_MESH', 'CONTROL_TYPE_CANNY')
                )

                subject_description = st.sidebar.text_area("Descript the image you uploaded", height=100, key="descriptions")
                edit_prompt = st.sidebar.text_area("Text in the edit prompts", height=100, key="edit_prompt")
                edit_generate_button = st.sidebar.button("Edit the Image")
                
        # Right column
        with right_col:            
            st.title("Google Imagen 3 Generates Image")
            text_to_highlight = """
            å›¾ç”Ÿå›¾çš„æç¤ºè¯æœ‰ä¸€äº›æŠ€å·§ \n
            å¦‚æœä½ æƒ³ç”ŸæˆåŒç±»äº§å“ï¼Œé‚£ä¹ˆä½ å…ˆä¸Šä¼ ä¸€å¼ ç…§ç‰‡ï¼Œç„¶åå¯ä»¥ä½¿ç”¨æç¤ºè¯æ¨¡ç‰ˆï¼Œåˆ‡è®°å¼•ç”¨çš„å›¾ç‰‡è¦ç”¨ [1] æ ‡å‡ºï¼š \n
            Create an image about SUBJECT_DESCRIPTION [1] to match the description: ${PROMPT} \n
            ä¾‹å¦‚ï¼šCreate an image about Luxe Elixir hair oil, golden liquid in glass bottle [1] to match the description: A close-up, high-key image of a woman's hand holding Luxe Elixir hair oil, golden liquid in glass bottle [1] against a pure white background. The woman's hand is well-lit and the focus is sharp on the bottle, with a shallow depth of field blurring the background and emphasizing the product. The lighting is soft and diffused, creating a subtle glow around the bottle and hand. The overall composition is simple and elegant, highlighting the product's luxurious appeal. \n
            \n
            å¦‚æœä½ æƒ³ç”Ÿæˆç›¸åŒç”»é£çš„äººï¼Œå…ˆä¸Šä¼ ä¸€å¼ ç…§ç‰‡ï¼Œç„¶åå¯ä»¥ä½¿ç”¨æç¤ºè¯æ¨¡ç‰ˆï¼Œåˆ‡è®°å¼•ç”¨çš„å›¾ç‰‡è¦ç”¨ [1] æ ‡å‡ºï¼š\n
            Generate an image of SUBJECT_DESCRIPTION [1]... \n
            ä¾‹å¦‚ï¼šGenerate an image of the girl [1] with a happy expression, looking directly at the camera. Her head should be tilted slightly to the right, and her hair should be styled in a way that is... \n
            \n
            å¦‚æœä½ æƒ³ç”Ÿæˆç›¸åŒçš„äººç‰©ï¼Œå…ˆä¸Šä¼ ä¸€å¼ ç…§ç‰‡ï¼Œç„¶åå¯ä»¥ä½¿ç”¨æç¤ºè¯æ¨¡ç‰ˆï¼Œåˆ‡è®°å¼•ç”¨çš„å›¾ç‰‡è¦ç”¨ [1] æ ‡å‡ºï¼š\n
            Generate an image of SUBJECT_DESCRIPTION [1] with the facemesh from the control image [2]. ${PROMPT} \n
            ä¾‹å¦‚ï¼šGenerate an image of the person [1] with the facemesh from the control image [2]. The person should be looking straight ahead with a neutral expression. The background should be a ... \n
            """
            st.info(text_to_highlight)

            col1, col2 = st.columns(2)

            with col1:
                origin_image = st.image("test.jpg", caption="Original Image", use_container_width=True)
            with col2:
                edit_image = st.image("test.jpg", use_container_width=True)

            st.markdown('<div class="centered-image">', unsafe_allow_html=True)
 
            if edit_generate_button:
                origin_image.image(uploaded_file)
                if not edit_prompt:
                    st.warning("æç¤ºè¯ä¸èƒ½ä¸ºç©º")
                    # st.stop()
                    return

                print("Start to generate image.\n")
                logging.info("Image generating.")
                logging.info(f"ç”¨æˆ·: {user_id} æ­£åœ¨ä½¿ç”¨å›¾ç”Ÿå›¾ï¼Œç”Ÿæˆä¸ªå›¾ç‰‡ï¼Œæç¤ºè¯ä¸º: {edit_prompt}")

                try:
                    image_data = uploaded_file.read()
                    image = types.Image(
                                image_bytes=image_data,
                                mime_type="image/png",
                            )

                    subject_reference_image = SubjectReferenceImage(
                        reference_id=1,
                        reference_image=image,
                        config=SubjectReferenceConfig(
                            subject_description=subject_description, 
                            subject_type=subject_type
                        ),
                    )
                    control_reference_image = ControlReferenceImage(
                        reference_id=2,
                        reference_image=image,
                        config=ControlReferenceConfig(control_type=control_type),
                    )

                    response = client.models.edit_image(
                        model='imagen-3.0-capability-001',
                        prompt=edit_prompt,
                        reference_images=[subject_reference_image, control_reference_image],
                        config=EditImageConfig(
                            edit_mode="EDIT_MODE_DEFAULT",
                            number_of_images=number_of_images,
                            seed=1,
                            safety_filter_level="BLOCK_ONLY_HIGH",
                            person_generation=person_generation,
                        ),
                    )

            
                    if response.generated_images:
                        edit_image.empty()
                        generated_image_object = response.generated_images[0]

                        image_displayed = False
                        # ä¸»è¦æ£€æŸ¥è·¯å¾„ï¼šgenerated_image_object.image.image_bytes
                        if hasattr(generated_image_object, 'image'):
                            image_container = generated_image_object.image
                            if hasattr(image_container, 'image_bytes'):
                                image_data = image_container.image_bytes
                                # å°è¯•è·å– mime_type
                                mime_type = getattr(image_container, 'mime_type', getattr(generated_image_object, 'mime_type', 'image/png'))
                                st.image(image_data, caption=f"Edited Image (MIME: {mime_type})")
                                image_displayed = True
                            elif hasattr(image_container, 'gcs_uri'):
                                image_uri = image_container.gcs_uri
                                mime_type = getattr(image_container, 'mime_type', getattr(generated_image_object, 'mime_type', 'N/A'))
                                st.warning(f"API returned GCS URI: {image_uri}")
                                st.image(image_uri, caption=f"Edited Image (from GCS URI, MIME: {mime_type})")
                                # !!! å¦‚æœ st.image æ— æ³•åŠ è½½ GCS URIï¼Œéœ€è¦æ·»åŠ  GCS ä¸‹è½½ä»£ç  !!!
                                image_displayed = True

                        # å¤‡ç”¨æ£€æŸ¥è·¯å¾„ (å¦‚æœ .image ä¸å­˜åœ¨æˆ–å†…éƒ¨æ²¡æœ‰æ•°æ®)
                        if not image_displayed:
                            if hasattr(generated_image_object, 'image_uri'):
                                image_uri = generated_image_object.image_uri
                                mime_type = getattr(generated_image_object, 'mime_type', 'N/A')
                                st.warning(f"API returned GCS URI directly: {image_uri}")
                                st.image(image_uri, caption=f"Edited Image (from GCS URI, MIME: {mime_type})")
                                # !!! å¦‚æœ st.image æ— æ³•åŠ è½½ GCS URIï¼Œéœ€è¦æ·»åŠ  GCS ä¸‹è½½ä»£ç  !!!
                                image_displayed = True

                        # å¦‚æœæ‰€æœ‰è·¯å¾„éƒ½å¤±è´¥
                        if not image_displayed:
                            st.error("Failed to find usable image data (bytes or URI) in the response object.")
                            st.write("GeneratedImage Object Details:", generated_image_object)

                    else:
                        st.error("å†…å®¹è¢«æ²³èŸ¹å•¦ã€‚ã€‚è¯·æ›´æ¢æç¤ºè¯ã€‚ã€‚è¯·æ›´æ¢æç¤ºè¯ æˆ–å›¾ç‰‡")
                        # å¯é€‰ï¼šæ‰“å°å®Œæ•´å“åº”è¿›è¡Œè°ƒè¯•
                        # st.write(response)
                except (TypeError, KeyError, requests.exceptions.RequestException) as e:
                    st.error(f"Error during image display: {e}")
                    st.error("å†…å®¹è¢«æ²³èŸ¹å•¦ã€‚ã€‚è¯·æ›´æ¢æç¤ºè¯")

    elif option == 'Image to Video':  # Edit Image mode
        # Left column
        with left_col:

            uploaded_file = st.sidebar.file_uploader("upload the image!", type=["jpg", "jpeg", "png"])

            with st.sidebar:
                frameOption = st.selectbox(
                    'frame',
                    ('16:9', '9:16')
                )
                fpsOption = st.sidebar.selectbox(
                    'fps',
                    ('24', '30')
                )
                duration_seconds = st.sidebar.selectbox(
                    'duration seconds',
                    ('5', '6', '7', '8')
                )
                person_generation = st.sidebar.selectbox(
                    'person generation options',
                    ('allow_adult', 'dont_allow')
                )
                enhance_prompt = st.sidebar.selectbox(
                    'Need Prompt enhancement?',
                    ('True', 'False')
                )
                number_of_videos = st.sidebar.selectbox(
                    'video number',
                    ('1', '2', '3', '4')
                )
            edit_opt_prompt_input = st.sidebar.text_area("Text in the prompts", height=100, key="edit_opt_prompt_input")
            edit_generate_button = st.sidebar.button("Generate Videos")
                
        # Right column
        with right_col:
            st.header("Google Veo 2 enable image to Video")
            text_to_highlight = "å½“ä»å›¾åƒç”Ÿæˆè§†é¢‘æ—¶ï¼Œå»ºè®®æ‚¨æä¾›ä¸€ä¸ªç®€å•çš„æ–‡æœ¬æç¤ºæ¥æè¿°æ‚¨æƒ³è¦çœ‹åˆ°çš„åŠ¨ä½œã€‚è¾“å…¥åœ¨é¡µé¢å·¦ä¸‹è§’çš„å¯¹è¯æ¡†é‡Œï¼ˆæœ€å¤š 10 ä¸ªè¯ï¼‰"
            st.info(text_to_highlight)

            col1, col2 = st.columns(2)
            with col1:
                origin_image = st.image("test.jpg", caption="Original Image", use_container_width=True)
            with col2:
                edit_image = st.image("test.jpg", caption="Video", use_container_width=True)

            if edit_generate_button:
                if uploaded_file is not None:
                    image_data = uploaded_file.read()
                    # æ˜¾ç¤ºä¸Šä¼ çš„åŸå§‹å›¾ç‰‡æ–‡ä»¶
                    logging.info(f'ç”¨æˆ·: {user_id} ä¸Šä¼ å›¾ç‰‡ï¼Œuploaded_file={uploaded_file.name}')
                    print('uploaded_file={}'.format(uploaded_file))
                    origin_image.image(uploaded_file)
                    output_gcs = "gs://xxxxxxxxxxxxxxx"  # @param {type: 'string'}
                    operation = None
                    try:
                        operation = client.models.generate_videos(
                            model="veo-2.0-generate-001",
                            prompt=edit_opt_prompt_input,
                            image=types.Image(
                                image_bytes=image_data,
                                mime_type="image/png",
                            ),
                            config=types.GenerateVideosConfig(
                                aspect_ratio=frameOption,
                                output_gcs_uri=output_gcs,
                                number_of_videos=number_of_videos,
                                duration_seconds=duration_seconds,
                                person_generation=person_generation,
                                enhance_prompt=enhance_prompt,
                                fps=fpsOption,
                            ),
                        )
                        logging.info(f"ç”¨æˆ·: {user_id} æ­£åœ¨ä½¿ç”¨å›¾ç”Ÿè§†é¢‘ï¼Œç”Ÿæˆ{number_of_videos}ä¸ªè§†é¢‘ï¼Œæç¤ºè¯ä¸º: {edit_opt_prompt_input}")

                    except Exception as submit_error:
                         st.error(f"æäº¤å›¾ç”Ÿè§†é¢‘ä»»åŠ¡å¤±è´¥: {submit_error}")
                         logging.error(f"ç”¨æˆ·: {user_id} å›¾ç”Ÿè§†é¢‘ä»»åŠ¡æäº¤å¤±è´¥ã€‚é”™è¯¯: {submit_error}", exc_info=True)
                         # å¯é€‰ï¼šè®°å½•æäº¤å¤±è´¥åˆ° Firestore
                         # log_details = {"error": str(submit_error), "status": "submission_failed"}
                         # log_api_call_to_firestore(db, user_id, "image_to_video_submit", details=log_details)
                         operation = None # ç¡®ä¿ operation ä¸º Noneï¼Œè·³è¿‡è½®è¯¢

                    if operation:    
                        while not operation.done:
                            time.sleep(15)
                            operation = client.operations.get(operation)
                            logging.info(f"Operation status: {operation}")
                            print(operation)

                        if operation and operation.response:
                            try:
                                logging.info("Video generating.")
                                edit_image.empty()
                                for video_object in operation.result.generated_videos:
                                    gcs_uri = video_object.video.uri
                                    display_video_from_gcs(gcs_uri)
        
                                    # è·å–æ“ä½œåç§°ç”¨äºæ—¥å¿—è®°å½• (å¦‚æœå¯ç”¨)
                                    op_name = "N/A"
                                    if hasattr(operation, '_operation') and hasattr(operation._operation, 'name'):
                                        op_name = operation._operation.name
                                    elif hasattr(operation, 'operation') and hasattr(operation.operation, 'name'):
                                        op_name = operation.operation.name

                                    log_details = {
                                        "prompt": edit_opt_prompt_input,
                                        "num_videos": number_of_videos,
                                        "duration": duration_seconds,
                                        "image_name": uploaded_file.name,
                                        "operation_name": op_name, # è®°å½•æ“ä½œå
                                        "GCS_location": gcs_uri
                                    }
                                    log_api_call_to_firestore(db, user_id, "image_to_video_submit", details=log_details) # è®°å½•æäº¤äº‹ä»¶
                                # show_image.video(operation.result.generated_videos[0].video.uri)
                                logging.info(f"ç”¨æˆ·: {user_id} è§†é¢‘ç”ŸæˆæˆåŠŸ")

                            except (TypeError, KeyError, requests.exceptions.RequestException) as e:
                                logging.error(f"Error during video display: {e}")
                                st.error("å†…å®¹è¢«æ²³èŸ¹å•¦ã€‚ã€‚")
                    
                        elif operation and operation.error: # æ£€æŸ¥æ“ä½œæ˜¯å¦åŒ…å«é”™è¯¯ä¿¡æ¯
                             logging.error(f"Operation failed: {operation.error.message}")
                             st.error(f"è§†é¢‘ç”Ÿæˆæ“ä½œå¤±è´¥: {operation.error.message}")
                             # å¯é€‰ï¼šè®°å½•æ“ä½œå¤±è´¥
                             # log_details = {"operation_name": op_name, "error": operation.error.message, "status": "failed"}
                             # log_api_call_to_firestore(db, user_id, "image_to_video_result", details=log_details)
        
                        else:
                            logging.error(f"Operation failed, operation.response is none, operation: {operation}")
                            if operation: # å¦‚æœ operation å­˜åœ¨ä½† response/error éƒ½ä¸ºç©º
                                st.error("è§†é¢‘ç”Ÿæˆæ“ä½œå®Œæˆï¼Œä½†çŠ¶æ€æœªçŸ¥æˆ–æ— æœ‰æ•ˆå“åº”ã€‚")
                                
    elif option == 'Text to Video':
        with left_col:
            with st.sidebar:
                aspect_ratio = st.selectbox(
                    'frame',
                    ('16:9', '9:16')
                )
                fpsOption = st.sidebar.selectbox(
                    'fps',
                    ('24', '30')
                )
                number_of_videos = st.sidebar.selectbox(
                    'video number',
                    ('1', '2', '3', '4')
                )
                duration_seconds = st.sidebar.selectbox(
                    'duration seconds',
                    ('5', '6', '7', '8')
                )
                person_generation = st.sidebar.selectbox(
                    'person generation options',
                    ('allow_adult', 'dont_allow')
                )
                enhance_prompt = st.sidebar.selectbox(
                    'Need Prompt enhancement?',
                    ('True', 'False')
                )
            opt_prompt_input = st.sidebar.text_area("The prompt after optimized", height=100, key="opt_prompt_input")
            generate_button = st.sidebar.button("Generate", key="generate_button")
                
        # Right column
        with right_col:
            st.title("Text to Video by Google Veo 2")
            text_to_highlight = """
            æ–‡æœ¬ç”Ÿè§†é¢‘çš„æç¤º åº”è¯¥æ¯”å›¾åƒåˆ°è§†é¢‘æ›´è¯¦ç»†ï¼Œä½¿ç”¨æ­£ç¡®çš„å…³é”®å­—å®ç°æ›´å¥½çš„æ§åˆ¶ã€‚
            æˆ‘ä»¬å·²ç¡®å®šäº†ä¸€äº›ä¸ Veo é…åˆè‰¯å¥½çš„å…³é”®å­—åˆ—è¡¨ï¼Œè¯·åœ¨æ‚¨çš„äººå·¥ä¹¦é¢æç¤ºä¸­ä½¿ç”¨è¿™äº›å…³é”®è¯æ¥è·å¾—æ‰€éœ€çš„ç›¸æœºåŠ¨ä½œæˆ–é£æ ¼
            æ¯”å¦‚ï¼š\n
            Subject(ç‰©ä½“): Who or what is the main focus of the shot e.g. happy woman in her 30s \n
            Sceneï¼ˆåœºæ™¯ï¼‰: Where is the location of the shot (on a busy street, in space) \n
            Actionï¼ˆåŠ¨ä½œï¼‰: What is the subject doing (walking, running, turning head) \n
            Camera Motionï¼ˆæ‘„åƒè½¨è¿¹ï¼‰: What the camera is doing e.g. POV shot, Aerial View, Tracking Drone view, Tracking Shot \n
            è¯•è¯•è¿™ä¸ªï¼šâ€œA cute creatures with snow leopard-like fur is walking in winter forest, 3D cartoon style render \n
            æˆ–è€…ï¼š An architectural rendering of a white concrete apartment building with flowing organic shapes, seamlessly blending with lush greenery and futuristic elements.
            """
            st.info(text_to_highlight)
            st.markdown('<div class="centered-image">', unsafe_allow_html=True)
            show_image = st.image("test.jpg", use_container_width =True)
            if generate_button:
                if not opt_prompt_input:
                    st.warning("æç¤ºè¯ä¸èƒ½ä¸ºç©º")
                    return

                # aspect_ratio = "16:9"  # @param ["16:9", "9:16"]
                output_gcs = "gs://xxxxxxxxxxxxxxx"  # @param {type: 'string'}

                operation = client.models.generate_videos(
                    model="veo-2.0-generate-001",
                    prompt=opt_prompt_input,
                    config=types.GenerateVideosConfig(
                        aspect_ratio=aspect_ratio,
                        output_gcs_uri=output_gcs,
                        number_of_videos=number_of_videos,
                        duration_seconds=duration_seconds,
                        person_generation=person_generation,
                        enhance_prompt=enhance_prompt,
                    ),
                )
                logging.info(f"ç”¨æˆ·: {user_id} æ­£åœ¨ä½¿ç”¨æ–‡ç”Ÿè§†é¢‘ï¼Œç”Ÿæˆ{number_of_videos}ä¸ªè§†é¢‘ï¼Œæç¤ºè¯ä¸º: {opt_prompt_input}")

                while not operation.done:
                    time.sleep(15)
                    operation = client.operations.get(operation)
                    logging.info(f"Operation status: {operation}")
                    print(operation)

                if operation.response:
                    try:
                        logging.info("Video generating.")
                        show_image.empty()
                        if len(operation.result.generated_videos) > 0:
                            for video_object in operation.result.generated_videos:
                                gcs_uri = video_object.video.uri
                                display_video_from_gcs(gcs_uri)
                                # è·å–æ“ä½œåç§°ç”¨äºæ—¥å¿—è®°å½• (å¦‚æœå¯ç”¨)
                                op_name = "N/A"
                                if hasattr(operation, '_operation') and hasattr(operation._operation, 'name'):
                                    op_name = operation._operation.name
                                elif hasattr(operation, 'operation') and hasattr(operation.operation, 'name'):
                                    op_name = operation.operation.name

                                log_details = {
                                    "prompt": opt_prompt_input,
                                    "duration": duration_seconds,
                                    "operation_name": op_name, # è®°å½•æ“ä½œå
                                    "GCS_location": gcs_uri
                                }
                                log_api_call_to_firestore(db, user_id, "text_to_video_submit", details=log_details) # è®°å½•æäº¤äº‹ä»¶
                            # show_image.video(operation.result.generated_videos[0].video.uri)
                            logging.info(f"ç”¨æˆ·: {user_id} è§†é¢‘ç”ŸæˆæˆåŠŸ")
                        else:
                            logging.error(f"Error during video display: {e}")
                            st.error("å†…å®¹è¢«æ²³èŸ¹å•¦ã€‚ã€‚")
                    except (TypeError, KeyError, requests.exceptions.RequestException) as e:
                        logging.error(f"Error during video display: {e}")
                        st.error("å†…å®¹è¢«æ²³èŸ¹å•¦ã€‚ã€‚")
                       
                else:
                    logging.error(f"Operation failed, operation.response is none, operation: {operation}")
        
    elif option == 'My Collections': # ä½¿ç”¨è‹±æ–‡ååŒ¹é…ä¸Šé¢ selectbox ä¸­çš„å€¼
        with right_col: # åœ¨å³ä¾§ä¸»åŒºåŸŸæ˜¾ç¤º
            st.title(f"ğŸ“œ {user_id} çš„è°ƒç”¨è®°å½•") # æ˜¾ç¤ºåŒ…å«ç”¨æˆ·åçš„æ ‡é¢˜

            if not user_id or "unknown" in user_id:
                st.warning("æ— æ³•è¯†åˆ«å½“å‰ç”¨æˆ·ï¼Œæ— æ³•æŸ¥è¯¢è®°å½•ã€‚")
            elif not db:
                 st.error("æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œæ— æ³•æŸ¥è¯¢è®°å½•ã€‚")
            else:
                # è·å–è¯¥ç”¨æˆ·çš„æ—¥å¿—è®°å½•
                user_logs = get_user_logs(db, user_id)

                if not user_logs:
                    st.info("æœªæ‰¾åˆ°æ‚¨çš„è°ƒç”¨è®°å½•ã€‚")
                else:
                    processed_data = []
                    for log in user_logs:
                        api_type = log.get('api_type', 'æœªçŸ¥ç±»å‹')
                        details = log.get('details', {})
                        prompt = details.get('prompt', 'N/A') # è·å–æç¤ºè¯ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä¸º 'N/A'
                        timestamp = log.get('timestamp', None) # è·å–æ—¶é—´æˆ³
                        cost = 0.0
                        GCS_location = details.get('GCS_location', None)

                        parts = str(GCS_location).replace("gs://", "").split("/")
                        bucket_name = parts[0]
                        source_blob_name = "/".join(parts[1:])
                        gcs_url = f"https://storage.mtls.cloud.google.com/{bucket_name}/{source_blob_name}"
                        
                        # ç¡®å®šæ“ä½œåç§°
                        operation_name = api_type # é»˜è®¤ä¸º api_type
                        if api_type == 'text_to_image':
                            operation_name = "æ–‡æœ¬ç”Ÿæˆå›¾ç‰‡"
                            cost = 1.0
                            processed_data.append({
                                "æ“ä½œåç§°": operation_name,
                                "ç”¨æˆ·æç¤ºè¯": prompt,
                                "æ—¶é—´": timestamp.strftime('%Y-%m-%d %H:%M:%S') if timestamp else "N/A", # æ ¼å¼åŒ–æ—¶é—´æˆ³
                                "è§†é¢‘è·¯å¾„": "None"
                            })
                        elif api_type in ['image_to_video_submit', 'text_to_video_submit']:
                            # ä» details ä¸­è·å–è§†é¢‘æ—¶é•¿
                            try:
                                duration = float(details.get('duration', 0)) # å°è¯•è½¬ä¸ºæµ®ç‚¹æ•°ï¼Œé»˜è®¤ä¸º 0
                            except (ValueError, TypeError):
                                duration = 0 # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œæ—¶é•¿è®¡ä¸º 0
                                print(f"è­¦å‘Š: åœ¨æ—¥å¿— {log.get('id','N/A')} ä¸­æœªèƒ½è§£æ duration_seconds: {details.get('duration_seconds')}")

                            cost = duration * 0.5
                            operation_name = "ç”Ÿæˆè§†é¢‘" if api_type == 'image_to_video_submit' else "æ–‡æœ¬ç”Ÿæˆè§†é¢‘"
                        # å¯ä»¥ä¸ºå…¶ä»– api_type æ·»åŠ æ›´å¤šè§„åˆ™

                            processed_data.append({
                                "æ“ä½œåç§°": operation_name,
                                "ç”¨æˆ·æç¤ºè¯": prompt,
                                "è´¹ç”¨ (Cost)": cost,
                                "æ—¶é—´": timestamp.strftime('%Y-%m-%d %H:%M:%S') if timestamp else "N/A", # æ ¼å¼åŒ–æ—¶é—´æˆ³
                                "è§†é¢‘è·¯å¾„": gcs_url
                            })

                    # åˆ›å»º Pandas DataFrame
                    df = pd.DataFrame(processed_data)

                    # é€‰æ‹©å¹¶é‡æ’è¦æ˜¾ç¤ºçš„åˆ—
                    display_df = df[["æ“ä½œåç§°", "ç”¨æˆ·æç¤ºè¯", "æ—¶é—´", "è§†é¢‘è·¯å¾„"]] 

                    # æ˜¾ç¤º DataFrame
                    st.dataframe(display_df, use_container_width=True)
                    # å¯é€‰ï¼šè®¡ç®—å¹¶æ˜¾ç¤ºæ€»è´¹ç”¨
                    # total_cost = df["è´¹ç”¨ (Cost)"].sum()
                    # st.metric("Total Estimated Cost", f"${total_cost:.2f}")
                    # st.write("å®é™…è´¹ç”¨ä»¥consoleè´¦å•ä¸ºä¸»")
                   

    else:
        st.title("TBD")        

if __name__ == "__main__":
    main()
   


